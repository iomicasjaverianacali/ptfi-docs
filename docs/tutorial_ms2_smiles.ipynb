{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03bc38b0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34905767",
   "metadata": {},
   "source": [
    "Neural network architectures are implemented in the files `MolecularStructureTeFT.py`, `MolecularStructureTeFTWithBias.py`, `MolecularStructureTeFTWithIntensity.py` (under test), `MolecularStructureTeFTWithMLP.py` (multi-task learning under revision).\n",
    "\n",
    "The tokenizer is implemented in `MolecularStructureDictionary.py`.\n",
    "\n",
    "The Training integrator is implemented in `TrainWorkFlowV2.py` (branch `v2`).\n",
    "\n",
    "The loss functions are defined as classes in `LossFunctions.py` (and for the multi-task learning also under the `LossWithMassPrediction.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028a172",
   "metadata": {},
   "source": [
    "The script used to train the neural network is named `train_teft_original_data_datadriven_tokenizer_v2.py` (the one in the `v2` branch).\n",
    "\n",
    "To check the arguments accepted by the script you can execute :\n",
    "\n",
    "```bash\n",
    "python train_teft_original_data_datadriven_tokenizer_v2.py --help\n",
    "```\n",
    "\n",
    "and after doing so, the list of arguments will be shown:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf332d4",
   "metadata": {},
   "source": [
    "- -h, --help            show this help message and exit\n",
    "-  *--max_sentence_size* : Maximum length of MS/MS to be considered\n",
    "-  *--tokenizer*: Tokenizer class name (Available options: DataDrivenTokenizer and SimpleTokenizer)\n",
    "-  *--dir_vocab*: path to the folder containing the tokenizer vocabulary (i.e. SPE_ChEMBL.txt)\n",
    "-  *--class_balancing*:     Enable class balancing\n",
    "-  *--balance_by*: Balance dataset by m/z values or molecular weights ('mz'or 'molecular_weight')\n",
    "-  *--balance_bins*: Number of bins to use for histogram when balancing the dataset\n",
    "-  *--batch_size*: Batch size for training\n",
    "-  *--device*: Device to use for training ('cpu' or 'cuda')\n",
    "-  *--loss_function*: Loss function to use for training ('CrossEntropy' or 'RegByMassCrossEntropy')\n",
    "-  *--architecture*: Available transformer-based architectures to use for training ('MolecularStructureTeFT' 'MolecularStructureTeFTWithBias', 'MolecularStructureTeFTWithIntensity')\n",
    "-  *--model_name*: Model name for saving\n",
    "- *--max_samples*: Maximum number of samples to use from the dataset. If None, use all samples.\n",
    "- *--epochs*: Number of training epochs\n",
    "- *--d_model*: Transformer architecture parameter emmbedding hidden size\n",
    "- *--d_ff*: Transformer architecture parameter feedForward dimension\n",
    "- *--d_k*: Transformer architecture parameter dimension of K( and Q)\n",
    "- *--d_v*: Transformer architecture parameter dimension of V\n",
    "- *--n_layers*: Number of Encoder/Decoder Layers\n",
    "- *--n_heads*: Number of heads in Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413f9742",
   "metadata": {},
   "source": [
    "In the command line execute:\n",
    "\n",
    "```bash\n",
    "python train_teft_original_data_datadriven_tokenizer_v2.py --max_sentence_size 100 --tokenizer DataDrivenTokenizer --dir_vocab /users/jdvillegas/ptfi-frijol-pujc-v2/data --batch_size 246 --device cuda --loss_function CrossEntropy --architecture MolecularStructureTeFTWithIntensity --model_name dd_su_arch3_lf1_code_pl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0226b6c7",
   "metadata": {},
   "source": [
    "Since training is very computing demanding, it is rather better to run it on the GPUs available in the cluster. \n",
    "\n",
    "To do so here is an example:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=dd_su_arch3_lf1_code_pl  # Job name\n",
    "#SBATCH -o dd_su_arch3_lf1_code_pl.out  # File to which STDOUT will be written, %j inserts jobid\n",
    "#SBATCH -e dd_su_arch3_lf1_code_pl.err  # File to which STDERR will be written, %j inserts jobid\n",
    "#SBATCH --partition=GPU # FULL if running CPU, GPU if running GPU, 3 GPUs with 24 GB each\n",
    "#SBATCH --nodes=1\n",
    "##SBATCH --tasks-per-node=12 # 40 CPUs per node\n",
    "##SBATCH --ntasks-per-socket=6 # 19 CPUs per socket\n",
    "##SBATCH --cpus-per-task=1 # 1 CPU per task\n",
    "#SBATCH --mem=200G # each node has around 380 GB, do not reserve all memory if you donÂ´t need all of it\n",
    "##SBATCH --nodelist=node22  # exactly which node to use, node 22 -> test node\n",
    "##SBATCH --exclude=node21   # which node to exclude\n",
    "#SBATCH --gres=gpu:3\n",
    "\n",
    "#module load lang/python/3.12.3\n",
    "#module load cuda/11.8\n",
    "\n",
    "# Source the Conda script to enable the `conda activate` command\n",
    "source ~/miniconda3/etc/profile.d/conda.sh  # Update this to your actual conda.sh path\n",
    "\n",
    "# Activate the specific Conda environment\n",
    "conda activate metabolomicscuda\n",
    "#conda activate wearmepylow\n",
    "\n",
    "scratch_dir=/scratch/jdvillegas/ptfi_$SLURM_JOB_ID\n",
    "\n",
    "mkdir -p $scratch_dir;\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/InputManagement.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/MolecularStructureDictionary.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/MolecularStructureTeFT.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/MolecularStructureTeFTWithBias.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/MolecularStructureTeFTWithIntensity.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/TrainWorkFlowWithIntensity.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/LossFunctions.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/Plotter.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/SignalMath.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/classes/TrainWorkFlowV2.py $scratch_dir\n",
    "cp -r /users/jdvillegas/ptfi-frijol-pujc-v2/scripts/train_teft_original_data_datadriven_tokenizer_v2.py $scratch_dir\n",
    "cd $scratch_dir\n",
    "\n",
    "# Run your Python script\n",
    "#time python train_teft_original_data_datadriven_tokenizer_v2.py\n",
    "time python train_teft_original_data_datadriven_tokenizer_v2.py --max_sentence_size 100 --tokenizer DataDrivenTokenizer --dir_vocab /users/jdvillegas/ptfi-frijol-pujc-v2/data --batch_size 246 --device cuda --loss_function CrossEntropy --architecture MolecularStructureTeFTWithIntensity --model_name dd_su_arch3_lf1_code_pl\n",
    "\n",
    "#mkdir $SLURM_SUBMIT_DIR/TeFT_DD_wo_reg_v2_nopad_nobal_dir_attn_$SLURM_JOB_ID\n",
    "#cp -r * $SLURM_SUBMIT_DIR/TeFT_DD_wo_reg_v2_nopad_nobal_dir_attn_$SLURM_JOB_ID\n",
    "\n",
    "cp -r $scratch_dir /users/jdvillegas/slurm_results/ptfi/$SLURM_JOB_ID\n",
    "\n",
    "echo \"TrainWorkflowV2 LF1 Arch3 (Intensity gating + Bias in Attention)\" > /users/jdvillegas/slurm_results/ptfi/$SLURM_JOB_ID/DescriptionBatchJob.txt\n",
    "#rm -r $scratch_dir\n",
    "\n",
    "# Deactivate the Conda environment\n",
    "conda deactivate\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e53636",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4369282b",
   "metadata": {},
   "source": [
    "The SMILES prediction is done by the `PredictWorkflow()` class of the `Workflow.py` file.\n",
    "\n",
    "Prediction can be done by executing the following snippet of code:\n",
    "\n",
    "```python\n",
    "from ptfifrijolpujc import PredictWorkflow\n",
    "\n",
    "pw = PredictWorkflow()\n",
    "pw.predict( List[List], # List of list of intensities\n",
    "            List[List], # List of list of m/z\n",
    "            smiles=List, # List of smiles\n",
    "            full_path_to_mdl=str, # full path to trained model\n",
    "            device=str, # either 'cpu' or 'cuda'\n",
    "            output_dir=str, # path to directory where to save results\n",
    "            num_pred=int, # number of SMILES predictions per MS/MS\n",
    "            predict_approach=str, # either \"beam_search\" or \"greedy\",\n",
    "            predict_approach_args=dict|None) # Only used when `predict_approach` is \"greedy. A dict with the only key `beam_size` (i.e. {'beam_size': 10})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a53f3",
   "metadata": {},
   "source": [
    "Working prediction examples `predict_known_metabolites_dec_2024.py` and `predict_CASMI_2022_modular.py` are avilable to use.\n",
    "\n",
    "- `predict_known_metabolites_dec_2024.py`: does predictions for a list of 314 known metabolites available in the file `path/to/the/repo/ptfi-frijol-pujc/data/Espectros_conocidos 1.xlsx`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2181f",
   "metadata": {},
   "source": [
    "To check the input parameters of `predict_known_metabolites_dec_2024.py`, set the current working directory to the `scripts` folder and execute:\n",
    "\n",
    "```bash\n",
    "python predict_known_metabolites_dec_2024.py --help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414c5a8",
   "metadata": {},
   "source": [
    "- *-h*, *--help*: show this help message and exit\n",
    "- *--dir_path*: Directory path containing the Excel file\n",
    "- *--filename*: Excel filename\n",
    "- *path_to_mdl*: Full path to the model directory\n",
    "- *--trained_model_name*: Name of the trained model file\n",
    "- *--output_dir*: Output directory for results\n",
    "- *--num_pred*: Number of predictions\n",
    "- *--predict_approach*: Prediction approach is either 'greedy' or 'beam_search'\n",
    "- *--device*: 'cpu' or 'cuda'\n",
    "- *--beam_size*: [OPTIONAL] Only if the `predict_approach` is 'beam_search', the length of the beam should be supplied as a dict (i.e. {`beam_size`: 5}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522b225",
   "metadata": {},
   "source": [
    "Specific example of use:\n",
    "\n",
    "```bash \n",
    "python predict_known_metabolites_dec_2024.py --dir_path /home/julian/Documents/repos/ptfi-frijol-pujc/data --filename Espectros_conocidos 1.xlsx --path_to_mdl /home/julian/Documents/FTP/ptfi/models --trained_model_name dd_arch1_lf1_data_1.pth --output_dir /home/julian/Documents/repos/ptfi-frijol-pujc/results/kn-dd-su-arch1-lf1-test --num_pred 10 --device cpu --predict_approach beam_search --beam_size 5\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
